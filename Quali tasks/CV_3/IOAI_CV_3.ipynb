{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transzfer-tanulás (60 + 30 pont)"
      ],
      "metadata": {
        "id": "ZzBvJtswgE3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A notebookot importáld be a Colab rendszerbe, majd abban dolgozz!**"
      ],
      "metadata": {
        "id": "OkRzeGX31frl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Versenyző neve: [ÍRD IDE A NEVED]**"
      ],
      "metadata": {
        "id": "W2oAJAnK_TmN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "eqabZHQ8r9yX"
      },
      "source": [
        "A modern mesterséges neurális hálók felé támasztott egyik elvárásunk, hogy képesek legyenek transzferálni az általuk már egy területen/feladaton elsajátított \"tudást\" más feladatok megoldására is. Például ha a hálónknak megtanítottuk már a kutyák és macskák megkülönböztetését, elvárhatjuk, hogy gyorsabban és kevesebb adatból is meg tudja már tanulni például a lovak és tigrisek megkülönböztetését. Ez számítási erőforrást és időt takarítana meg számunkra, kevés adaton is lehetővé tenné a tanítást, és  potenciálisan javíthatná a modellek teljesítményét a különböző feladatokon. Sajnos általánosan érvényes, garantáltan működő módszer a tudás-transzfer biztosítására nincs egyelőre, a transzfer-tanulás sikeressége adat- és modell-függő a legtöbbször. Ezekben a feladatokban azt fogjuk vizsgálni, hogy hogyan és mikor, mennyire sikeresen működik a transzfer tanulás. A transzfer tanulásról bővebben olvashattok [ebben a jegyzetben](https://cs231n.github.io/transfer-learning/), illetve [ebben a pytorch tutorialban](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Részfeladatok\n",
        "\n",
        "Ez a feladat több részfeladatból áll, ezeket bármilyen sorrendben választhatod, de javasoljuk, hogy nagyjából sorban haladj.\n",
        "\n",
        "Az utolsó feladat egy általatok választott rövid projekt, a feladat témakörén belül. Ebben a notebookban legfeljebb egy ilyet adhatsz be (de vannak ilyen miniprojektek más feladatokban)\n",
        "\n",
        "Feladatok (`60 + 30`):\n",
        "1. `5 pont` Modell-kiértékelés (pytorch, hibafüggvények)\n",
        "1. `10 pont` Transzfer tanítás nélkül (pytorch, torchvision, pretrained models)\n",
        "1. `10 pont` Beágyazás-vektorok kiszámolása (pytorch)\n",
        "1. `5 pont` Adatbetöltés (pytorch, dataloaders)\n",
        "1. `15 pont` Transzfer tanítás (pytorch, tanítás, matplotlib, értelmezés)\n",
        "1. `15 pont` Modellek távolságának számítása (pytorch, matplotlib)\n",
        "1. `30 pont` **Szabadon értelmezhető miniprojekt** (Te találod ki, mit csinálsz)\n"
      ],
      "metadata": {
        "id": "ckoU7yKnobwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Előkészületek"
      ],
      "metadata": {
        "id": "Jqv_AqHVOK8D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mwIXxHyMr9yc"
      },
      "source": [
        "\n",
        "### Könyvtárak betöltése, beállítások"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "aUS3StJTr9yd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A reprodukálható eredmények érdekében elengedhetetlen, hogy rögzítsük a véletlenszám generátor seed-jét."
      ],
      "metadata": {
        "id": "Xxfud6rA8Sd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "X16dOfdhr9yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e00c2b1-b1e3-4e61-f78e-ebbbee68a23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A random seed értéke: 2024\n",
            "WARNING: A notebook  jelenleg nem használ GPU gyorsítást, ha lehetséges, a menüben a `Runtime` -> `Change runtime type` opciónál választ a `GPU`-t \n"
          ]
        }
      ],
      "source": [
        "# for DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "    if seed is None:\n",
        "        seed = np.random.choice(2 ** 32)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if seed_torch:\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    print(f'A random seed értéke: {seed}')\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if device != \"cuda\":\n",
        "        print(\"WARNING: A notebook  jelenleg nem használ GPU gyorsítást, \"\n",
        "              \"ha lehetséges, a menüben a `Runtime` -> \"\n",
        "              \"`Change runtime type` opciónál választ a `GPU`-t \")\n",
        "    else:\n",
        "        print(\"GPU használható a notebookban.\")\n",
        "\n",
        "    return device\n",
        "\n",
        "set_seed(seed=2024)\n",
        "device = set_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "AMUZhHfnr9yj"
      },
      "source": [
        "---\n",
        "### A CIFAR-10 és CIFAR-100 adathalmaz betöltése\n",
        "\n",
        "A CIFAR-10 és a CIFAR-100 is színes képet tartalmazó adathalmaz 50000 tanító és 10000 teszt képpel, ezek 32 x 32 pixelből állnak, és összesen 10, illetve 100 különböző kategóriából lehetnek, mindegyik kép rendelkezik címkével. A `torchvision.datasets.cifar.CIFAR` objetumon keresztül érhető el mindkét adathalmaz, onnan töltjük be őket, előre beállítjuk, hogy ne használjunk adataugmentálást és 256 kép legyen egy batch-nyi adat."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(dataset_name, batch_size=256, augmentation=False):\n",
        "    normalization_data = {'CIFAR100': ((0.5071, 0.4866, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
        "                          'CIFAR10': ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))}\n",
        "\n",
        "    transform_train = transforms.Compose([])\n",
        "    if augmentation:\n",
        "        transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "        transform_train.transforms.append(transforms.RandomHorizontalFlip())\n",
        "\n",
        "    transform_train.transforms.append(transforms.ToTensor())\n",
        "    transform_train.transforms.append(transforms.Normalize(mean=normalization_data[dataset_name][0],\n",
        "                                                           std=normalization_data[dataset_name][1]))\n",
        "\n",
        "    transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize(mean=normalization_data[dataset_name][0],\n",
        "                                                              std=normalization_data[dataset_name][1])])\n",
        "    if dataset_name == 'CIFAR100':\n",
        "        dataclass = torchvision.datasets.CIFAR100\n",
        "    elif dataset_name == 'CIFAR10':\n",
        "        dataclass = torchvision.datasets.CIFAR10\n",
        "\n",
        "    trainset = dataclass(root=f'./{dataset_name}', train=True, download=True, transform=transform_train)\n",
        "    testset = dataclass(root=f'./{dataset_name}', train=False, download=True, transform=transform_test)\n",
        "\n",
        "    print(f\"Objektum: {type(trainset)}\")\n",
        "    print(f\"Tanító adatok shape-je: {trainset.data.shape}\")\n",
        "    print(f\"Teszt adatok shape-je: {testset.data.shape}\")\n",
        "    print(f\"Az osztályok száma: {np.unique(trainset.targets).shape[0]}\")\n",
        "\n",
        "    num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "cifar100_trainloader, cifar100_testloader = get_dataloaders('CIFAR100')\n",
        "cifar10_trainloader, cifar10_testloader = get_dataloaders('CIFAR10')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1_TGhVbeEBn",
        "outputId": "b9166b21-b578-49c6-fb3b-4f4483e4ec1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Objektum: <class 'torchvision.datasets.cifar.CIFAR100'>\n",
            "Tanító adatok shape-je: (50000, 32, 32, 3)\n",
            "Teszt adatok shape-je: (10000, 32, 32, 3)\n",
            "Az osztályok száma: 100\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Objektum: <class 'torchvision.datasets.cifar.CIFAR10'>\n",
            "Tanító adatok shape-je: (50000, 32, 32, 3)\n",
            "Teszt adatok shape-je: (10000, 32, 32, 3)\n",
            "Az osztályok száma: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "OXOAQY45r9yl"
      },
      "source": [
        "### Betanított ResNet modellek betöltése\n",
        "\n",
        "A ResNet hálóarchitektúra igen népszerű és jó eredményeket elérő modellcsalád alapja, fő jellemzője, hogy reziduális blokkokból áll. A reziduális blokkokon belül jól ismert rétegtípusok, konvolúciós, pooling, bacth normalizáló rétegek találhatóak, és a blokk bemenetét a kimenetéhez adva egy speciális úgynevezett _shortcut_ vagy _skip connection_ is van. Az [eredeti cikkben](https://arxiv.org/abs/1512.03385) további részleteket olvashattok. A modellcsaládban különböző mélységű modelleket lehet konstruálni a blokkok számának növelésével, pl. ResNet-18, ResNet-32, ResNet-50. A ResNet-20 modell abban tér el ezektől, hogy míg az előbbiek inkább nagyobb méretű képek feldolgozására alkalmasak (pl. ImageNet), addig a ResNet-20 kisebb konvolúciós filterekkel operál, a CIFAR adathalmazok kisebb inputméretéhez alakítva. Az alábbi kód betölt a torchhub-ról [két betanított modellt, amelyekről további információt találtok ezen a github linken](https://github.com/chenyaofo/pytorch-cifar-models/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.hub.list(\"chenyaofo/pytorch-cifar-models\", force_reload=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig-cK_IeID-N",
        "outputId": "072d909a-2a7d-4d75-d1fc-c3ecc6ecdf51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or list(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use list(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cifar100_mobilenetv2_x0_5', 'cifar100_mobilenetv2_x0_75', 'cifar100_mobilenetv2_x1_0', 'cifar100_mobilenetv2_x1_4', 'cifar100_repvgg_a0', 'cifar100_repvgg_a1', 'cifar100_repvgg_a2', 'cifar100_resnet20', 'cifar100_resnet32', 'cifar100_resnet44', 'cifar100_resnet56', 'cifar100_shufflenetv2_x0_5', 'cifar100_shufflenetv2_x1_0', 'cifar100_shufflenetv2_x1_5', 'cifar100_shufflenetv2_x2_0', 'cifar100_vgg11_bn', 'cifar100_vgg13_bn', 'cifar100_vgg16_bn', 'cifar100_vgg19_bn', 'cifar100_vit_b16', 'cifar100_vit_b32', 'cifar100_vit_h14', 'cifar100_vit_l16', 'cifar100_vit_l32', 'cifar10_mobilenetv2_x0_5', 'cifar10_mobilenetv2_x0_75', 'cifar10_mobilenetv2_x1_0', 'cifar10_mobilenetv2_x1_4', 'cifar10_repvgg_a0', 'cifar10_repvgg_a1', 'cifar10_repvgg_a2', 'cifar10_resnet20', 'cifar10_resnet32', 'cifar10_resnet44', 'cifar10_resnet56', 'cifar10_shufflenetv2_x0_5', 'cifar10_shufflenetv2_x1_0', 'cifar10_shufflenetv2_x1_5', 'cifar10_shufflenetv2_x2_0', 'cifar10_vgg11_bn', 'cifar10_vgg13_bn', 'cifar10_vgg16_bn', 'cifar10_vgg19_bn', 'cifar10_vit_b16', 'cifar10_vit_b32', 'cifar10_vit_h14', 'cifar10_vit_l16', 'cifar10_vit_l32']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)\n",
        "cifar100_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_resnet20\", pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFqa7a3MJLZw",
        "outputId": "3c9775ec-4c17-4cf0-a4a1-69584e41af97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n",
            "100%|██████████| 1.09M/1.09M [00:00<00:00, 21.1MB/s]\n",
            "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar100_resnet20-23dac2f1.pt\" to /root/.cache/torch/hub/checkpoints/cifar100_resnet20-23dac2f1.pt\n",
            "100%|██████████| 1.11M/1.11M [00:00<00:00, 18.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxQSq9mFJOD0",
        "outputId": "d69ac312-0bdb-4fb4-b674-a0805638aefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CifarResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar100_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcPAZ4PlKM12",
        "outputId": "d8529899-19bd-4d1c-eb47-26e2ed6203f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CifarResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beágyazás-vektorok letöltése\n",
        "\n",
        "Hogy a számításokat leegyszerűsítsük, előre legeneráltuk nektek a fennebb betöltött CIFAR-100-on tanított modellel a CIFAR-10 tanító adathalmaz beágyazásvektorait, a modell utolsó-előtti rétegének kimeneteit, amelyeken sokkal gyorsabb már egy lineáris kimeneti réteget betanítani. [Ezek a beágyazás-vektorok itt elérhetőek](https://drive.google.com/file/d/1NU-TEU5w1Fhqm4NT6rmJbBspdI5QeMoA/view?usp=drive_link), a fájl egy (50000, 64, 1, 1) alakú és egy (50000) alakú tensort tartalmaz a beágyazásvektorokkal  és a nekik megfelelő címkékkel. Manuálisan is le lehet tölteni, de az alább megadott kód már be is tölti nektek tensor-okként ezeket."
      ],
      "metadata": {
        "id": "8ZonanefQYKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://drive.google.com/uc?id=1NU-TEU5w1Fhqm4NT6rmJbBspdI5QeMoA&export=download' -O /content/cifar10_embeddings_and_labels.pt\n",
        "\n",
        "cifar10_embeddings, labels = torch.load('/content/cifar10_embeddings_and_labels.pt', map_location=torch.device('cpu'))\n",
        "\n",
        "print('Beágyazás-vektorok tenzorának mérete: ', cifar10_embeddings.shape)\n",
        "print('Címkék tenzorának mérete: ', labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n7mLVSQQgPU",
        "outputId": "868fd47b-69da-492d-abf4-c74551e34bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-30 02:10:04--  https://drive.google.com/uc?id=1NU-TEU5w1Fhqm4NT6rmJbBspdI5QeMoA&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.214.102, 172.217.214.138, 172.217.214.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.214.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1NU-TEU5w1Fhqm4NT6rmJbBspdI5QeMoA&export=download [following]\n",
            "--2024-05-30 02:10:04--  https://drive.usercontent.google.com/download?id=1NU-TEU5w1Fhqm4NT6rmJbBspdI5QeMoA&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.193.132, 2607:f8b0:4001:c0f::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.193.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13201806 (13M) [application/octet-stream]\n",
            "Saving to: ‘/content/cifar10_embeddings_and_labels.pt’\n",
            "\n",
            "/content/cifar10_em 100%[===================>]  12.59M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-05-30 02:10:08 (168 MB/s) - ‘/content/cifar10_embeddings_and_labels.pt’ saved [13201806/13201806]\n",
            "\n",
            "Beágyazás-vektorok tenzorának mérete:  torch.Size([50000, 64, 1, 1])\n",
            "Címkék tenzorának mérete:  torch.Size([50000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **1\\. Feladat - Modell-kiértékelés (5 pont)**\n",
        "\n",
        "Implementálj egy hasznos segédfüggvényt, amely paraméterként egy pytorch modellt és egy adatloadert kap, és azt csinálja, hogy az adatloader által betöltött adatokon osztályozás szempontjából kiértékeli a modellt: kiszámolja az átlagos pontosságot és az átlagos keresztentrópia hibafüggvény-értéket, ezt a két számot téríti vissza. Figyelj arra, hogy kiértékeléskor be kell állítani, hogy a modelt evaluáljuk csak, nem tanítjuk (ennek függvényében például változik a BatchNorm működése is), illetve arra, hogy gradiensszámolás ilyenkor ne történejen semmiképp. Teszteld a függvényed egy már betöltött modellel és tesztadat-loaderrel."
      ],
      "metadata": {
        "id": "h05yWB2dmCcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A megoldásod\n",
        "\n",
        "Használj kód- és szövegcellákat szükség szerint."
      ],
      "metadata": {
        "id": "NeHAuZSuzZqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2\\. Feladat - Transzfer tanítás előtt (10 pont)**\n",
        "\n",
        "\n",
        "Töltsd be két ResNet-20 modellt: az egyik legyen a CIFAR-100 adathalmazon osztályozásra betanítva, a másik pedig a CIFAR-10 adathalmazon, ehhez találsz segítséget a megadott kódban, illetve [a github oldalon](https://github.com/chenyaofo/pytorch-cifar-models/), ahonnan a betöltött modellek származnak. Írd le, milyen pontosságot érnek el a megfelelő teszt-halmazokon. Cseréld ki a CIFAR-100 adaton tanított modell utolsó rétegét a CIFAR-10 adaton tanított modellével. Számold ki az így kapott háló pontosságát a CIFAR-10 teszt-halmazán, és hasonlítsd össze egy véletlenszerűen inicializált megfelelő ResNet-20 háló CIFAR-10 teszt-halmazon mért teljesítményével, hogy kiderüljön, történik-e a tudás-transzfer továbbtanítás nélkül a CIFAR-100-ról. Fogalmazd meg szövegesen a kapott eredményeket.\n"
      ],
      "metadata": {
        "id": "r342USbcMNLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A megoldásod"
      ],
      "metadata": {
        "id": "Wz7_lfQCzx0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3\\. Feladat - Beágyazás-vektorok (10 pont)**\n",
        "\n",
        "A transzfer tanulás során a forrás-adathalmazon (esetünkben ez a CIFAR-100 lesz) betanított modellt - tipikusan elegendő annak csak az utolsó rétegét - a cél-adaton (esetünkben a CIFAR-10) tanítjuk, úgymond finomhangoljuk. Hogy a számításokat leegyszerűsítsük, előre legeneráltuk nektek a fennebb betöltött CIFAR-100-on tanított modellel a CIFAR-10 tanító adathalmaz beágyazásvektorait, a modell utolsó-előtti rétegének kimeneteit, amelyeken sokkal gyorsabb már egy lineáris kimeneti réteget betanítani. [Ezek a beágyazás-vektorok itt elérhetőek](https://drive.google.com/file/d/1NU-TEU5w1Fhqm4NT6rmJbBspdI5QeMoA/view?usp=drive_link), a fájl egy (50000, 64, 1, 1) alakú és egy (50000) alakú tensort tartalmaz a beágyazásvektorokkal  és a nekik megfelelő címkékkel. Manuálisan is le lehet tölteni, de az alább megadott kód már be is tölti nektek tensor-okként ezeket. Egy batch-nyi adaton számold ki te is ezeket a beágyazás-vektorokat és ellenőrizd, hogy ezek megegyeznek az általunk megadottakkal, tudva, hogy a megadott kódban a random seed rögzítése miatt a megadott adatloader ugyanabban a sorrendben tölti be az adatokat, mint ahogyan a beágyazásvektorok számításakor mi is használtuk, és nem engedtük, hogy az adatbetöltő összekeverje az adatokat (azaz a shuffle paraméterét False-ra állítottuk). Elegendő, ha az abszolút eltérés közöttük kevesebb, mint 0.0001."
      ],
      "metadata": {
        "id": "u5kvgOjIMz_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A megoldásod"
      ],
      "metadata": {
        "id": "q497qyRoznK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4\\. Feladat - Adatbetöltés (5 pont)**\n",
        "\n",
        "A megadott beágyazásvektorokhoz társítsd hozzá a megfelelő osztálycímkéket, tudva, hogy a megadott kódban a random seed rögzítése miatt a megadott adatloader ugyanabban a sorrendben tölti be az adatokat, mint ahogyan a beágyazásvektorok számításakor mi is használtuk (tehát a beágyazásvektorok ugyanabban a sorrendben vannak megadva nektek). Állíts elő egy adatloadert, ami már a beágyazásvektorokon való tanításhoz tölti be batch-enként az adatokat."
      ],
      "metadata": {
        "id": "EGTucACQNAko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A megoldásod"
      ],
      "metadata": {
        "id": "_2Cdh8Baz2Er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5\\. Feladat - Transzfer tanítás (15 pont)**\n",
        "\n",
        "Alkalmasan megválasztott paraméterekkel taníts az előző feladatban megadott beágyazásvektorokon egy egyetlen lineáris rétegből álló modellt a CIFAR-10 adathalmazon osztályozásra. Ez a CIFAR-100-on tanított modell CIFAR-10-en való transzfer tanításának felel meg. A tanítás után a CIFAR100-on betanított modell kimeneti rétegét cseréld le az újonnan betanított lineáris rétegre. Ha már sikerül jól betanítani a lineáris modellt, ábrázold egy ábrán a tanítási epochok számának függvényében, legalább 5 epochon keresztül, hogyan változik a lineáris réteg tanítása során a módosított háló pontossága a CIFAR-10 teszt-halmazán."
      ],
      "metadata": {
        "id": "2zPHtqaDNggY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A megoldásod"
      ],
      "metadata": {
        "id": "g-HIWGcj0C9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6\\. Feladat - Modellek távolsága (15 pont)**\n",
        "\n",
        "Számold ki három modell paramétereinek a páronkénti $L_2$-távolságát. A három összehasonlított modell legyen a CIFAR-10 osztályozására véletlenszerűen inicializiált, a CIFAR-10-en betanított modell, és a CIFAR-100-on tanított modell az 5. feladatban betanított lineáris rétegre lecserélt kimeneti réteggel - részpontszámért ez lehet a CIFAR-10-en betanított modell kimeneti rétegére cserélt is. Jelenítsd meg képként a páronkénti távolságokat egy 3x3 alakú mátrixban, amelynek a cellái az távolság-értékek alapján vannak beszínezve. Fogalmazd meg szövegesen, hogyan értelmezed a kapott értékeket."
      ],
      "metadata": {
        "id": "iYqU_69I0BTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A megoldásod"
      ],
      "metadata": {
        "id": "fDo30edY0F61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7\\. Feladat -  Miniprojekt - önálló exploráció (30 pont)**\n",
        "\n",
        "Ha a többi részfeladatot nagyrészt megoldottad, most rád bízzuk, hogy milyen kiegészítéseket szertnél még implementálni a témával kapcsolatban. Itt van néhány példa:\n",
        "\n",
        "* Speciális hibafüggvény implementálása transzfer tanuláshoz\n",
        "* Transzfer tanítás szürkeáryalatos képi adathalmazra\n",
        "* Vizualizáció például t-SNE segítségével, mennyire klasztereződnek a CIFAR-10 megadott beágyazásvektorai\n",
        "\n",
        "Minden miniprojektért (ebben a notebookban csak egyet adhatsz be, de az NLP-4, CV-4 notebookokban is lehet) max *30 pont* jár. Egy 30 pontos projekt jellemzői:\n",
        "* **motiváció és kreativitás:** érdekes, kreatív projekt, jó motiváció, hipotézisek-kérdések-célok egyértelmű leírása, referenciák az irodalomra, ahol releváns\n",
        "* **implementáció:** nem-triviális munka, ami demonstrálja a technikai felkészültséget, helyes implementáció, jó eszközválasztás, kompakt és olvasható kód\n",
        "* **kiértékelés és konklúziók:** fair és részletes kiértékelés, ábrák kiváló használata (feliratok, címkék, stb.), tömör de célratörő konklúzió."
      ],
      "metadata": {
        "id": "QQ0imvq40SrA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkLdyM580wkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "OXOAQY45r9yl",
        "h05yWB2dmCcp",
        "r342USbcMNLz",
        "u5kvgOjIMz_3",
        "EGTucACQNAko",
        "2zPHtqaDNggY",
        "QQ0imvq40SrA"
      ]
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}